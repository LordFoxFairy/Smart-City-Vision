{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e351e33f-8ca4-4759-b36b-616d6945cb43",
   "metadata": {},
   "source": [
    "# LLAMA-Factory微调模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7005e556-e70e-4ea5-95d3-f613dd327dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple\n",
      "Collecting deepspeed\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/0d/88/96569b2acb3219c9c72068f9b952c59beffe366e7d1edd9e922e5c68f08b/deepspeed-0.16.5.tar.gz (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "  Preparing metadata (setup.py) ... \u001b[done\n",
      "\u001b[?25hRequirement already satisfied: einops in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from deepspeed) (0.8.1)\n",
      "Collecting hjson (from deepspeed)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/1f/7f/13cd798d180af4bf4c0ceddeefba2b864a63c71645abc0308b768d67bb81/hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: msgpack in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from deepspeed) (1.1.0)\n",
      "Collecting ninja (from deepspeed)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/eb/7a/455d2877fe6cf99886849c7f9755d897df32eaf3a0fba47b56e615f880f7/ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Requirement already satisfied: numpy in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from deepspeed) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from deepspeed) (24.2)\n",
      "Requirement already satisfied: psutil in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from deepspeed) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from deepspeed) (2.10.6)\n",
      "Requirement already satisfied: torch in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from deepspeed) (2.5.1+cu121)\n",
      "Requirement already satisfied: tqdm in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from deepspeed) (4.67.1)\n",
      "Requirement already satisfied: nvidia-ml-py in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from deepspeed) (12.570.86)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (3.17.0)\n",
      "Requirement already satisfied: networkx in /home/zhangsh82/.local/lib/python3.10/site-packages (from torch->deepspeed) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/zhangsh82/.local/lib/python3.10/site-packages (from torch->deepspeed) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->deepspeed) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zhangsh82/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch->deepspeed) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zhangsh82/.local/lib/python3.10/site-packages (from jinja2->torch->deepspeed) (2.1.5)\n",
      "Building wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) done\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.16.5-py3-none-any.whl size=1580682 sha256=ed265b736e5fdaced9356ce3ae0b275889b4ff45df40bb0398478f1d24fe2f27\n",
      "  Stored in directory: /home/zhangsh82/.cache/pip/wheels/15/b3/d2/9123c71066491c377366a0fb72143f432e86d370ce08634663\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: hjson, ninja, deepspeed\n",
      "Successfully installed deepspeed-0.16.5 hjson-3.1.0 ninja-1.11.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc55733-4203-4f2e-9d87-5fdef45fa89e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple\n",
      "Collecting flash-attn\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/11/34/9bf60e736ed7bbe15055ac2dab48ec67d9dbd088d2b4ae318fd77190ab4e/flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "  Preparing metadata (setup.py) ... \u001b[?25done\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from flash-attn) (2.5.1+cu121)\n",
      "Requirement already satisfied: einops in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from flash-attn) (0.8.1)\n",
      "Requirement already satisfied: filelock in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/zhangsh82/.local/lib/python3.10/site-packages (from torch->flash-attn) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/zhangsh82/.local/lib/python3.10/site-packages (from torch->flash-attn) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch->flash-attn) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zhangsh82/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zhangsh82/.local/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp310-cp310-linux_x86_64.whl size=187797312 sha256=b267f80a08e516292cdd748056a2178a45b8abedf7fca123292eb17c21c8c87c\n",
      "  Stored in directory: /home/zhangsh82/.cache/pip/wheels/34/f4/ae/aebe0077ed247cabb5a74b211ffbbdb3f84147016aa2cae4ac\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: flash-attn\n",
      "Successfully installed flash-attn-2.7.4.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abaec634-f920-4932-bbee-0ee3307d18ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正克隆到 'LLaMA-Factory'...\n",
      "remote: Enumerating objects: 353, done.\u001b[K\n",
      "remote: Counting objects: 100% (353/353), done.\u001b[K\n",
      "remote: Compressing objects: 100% (281/281), done.\u001b[K\n",
      "remote: Total 353 (delta 94), reused 183 (delta 57), pack-reused 0 (from 0)\u001b[K\n",
      "接收对象中: 100% (353/353), 9.70 MiB | 9.97 MiB/s, 完成.\n",
      "处理 delta 中: 100% (94/94), 完成.\n"
     ]
    }
   ],
   "source": [
    "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb5d8f9-1c6d-4101-8dd3-b1704a135288",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple\n",
      "Obtaining file:///home/zhangsh82/data/zsh/LLaMA-Factory\n",
      "  Installing build dependencies ... \u001b[done\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.1,>=4.41.2 (from llamafactory==0.9.3.dev0)\n",
      "  Using cached https://mirrors.cloud.tencent.com/pypi/packages/73/e0/f1fce1b2f31da4acfb858732d909209fdb10f65adda1e7af0c7ac74927a5/transformers-4.51.1-py3-none-any.whl (10.4 MB)\n",
      "Requirement already satisfied: datasets<=3.5.0,>=2.16.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (2.21.0)\n",
      "Requirement already satisfied: accelerate<=1.6.0,>=0.34.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (1.6.0)\n",
      "Collecting peft<=0.15.1,>=0.14.0 (from llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/d5/47/f2938c20b1c6d7b738ca2a129cf73cd1453cea76d5c9a2f2bbf6199bf037/peft-0.15.1-py3-none-any.whl (411 kB)\n",
      "Collecting trl<=0.9.6,>=0.8.6 (from llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/a5/c3/6565c2c376a829f99da20d39c2912405195ec1fa6aae068dc45c46793e72/trl-0.9.6-py3-none-any.whl (245 kB)\n",
      "Requirement already satisfied: tokenizers<=0.21.0,>=0.19.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (0.21.0)\n",
      "Collecting gradio<=5.21.0,>=4.38.0 (from llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/93/e9/dfc030f623a8c5efce02b853cfe1b9a47dd1365cc028926800b5757308f1/gradio-5.21.0-py3-none-any.whl (46.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (2.0.3)\n",
      "Requirement already satisfied: scipy in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (1.10.1)\n",
      "Requirement already satisfied: einops in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (0.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (0.9.0)\n",
      "Requirement already satisfied: protobuf in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (5.29.3)\n",
      "Requirement already satisfied: uvicorn in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (0.34.0)\n",
      "Requirement already satisfied: pydantic in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (2.10.6)\n",
      "Requirement already satisfied: fastapi in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (0.115.8)\n",
      "Collecting sse-starlette (from llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/d9/e0/5b8bd393f27f4a62461c5cf2479c75a2cc2ffa330976f9f00f5f6e4f50eb/sse_starlette-2.2.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (3.7.2)\n",
      "Collecting fire (from llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/6b/b6/82c7e601d6d3c3278c40b7bd35e17e82aa227f050aa9f66cb7b7fce29471/fire-0.7.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (6.0.2)\n",
      "Requirement already satisfied: numpy<2.0.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from llamafactory==0.9.3.dev0) (1.26.4)\n",
      "Collecting av (from llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/4c/86/292aa2aee50902d55ea8cb94e6d6112d20884b340a6d75f8521f671c8556/av-14.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting librosa (from llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/b5/ba/c63c5786dfee4c3417094c4b00966e61e4a63efecee22cb7b4c0387dda83/librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Collecting tyro<0.9.0 (from llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/60/ec/e34d546cfd9c5b906d1d534bb75557be9f2b179609d60bb9e97ec07e8ead/tyro-0.8.14-py3-none-any.whl (109 kB)\n",
      "Requirement already satisfied: psutil in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (2.5.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (0.5.2)\n",
      "Requirement already satisfied: filelock in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (3.11.12)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (4.8.0)\n",
      "Collecting ffmpy (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/53/5d/65f40bd333463b3230b3a72d93873caaf49b0cbb5228598fafb75fcc5357/ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Collecting gradio-client==1.7.2 (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/95/cb/002424d4f5af1425f9cfe7dcee3ed795ed1367bf0f185a6c4bf81385e1d6/gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
      "Collecting groovy~=0.1 (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/28/27/3d6dcadc8a3214d8522c1e7f6a19554e33659be44546d44a2f7572ac7d2a/groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/zhangsh82/.local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/zhangsh82/.local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/zhangsh82/.local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (2.1.5)\n",
      "Collecting orjson~=3.0 (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/2c/71/73a1214bd27baa2ea5184fff4aa6193a114dfb0aa5663dad48fe63e8cd29/orjson-3.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (11.0.0)\n",
      "Collecting pydub (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/45/58/38b5afbc1a800eeea951b9285d3912613f2603bdf897a4ab0f4bd7f405fc/python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Collecting ruff>=0.9.3 (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/63/80/734d3d17546e47ff99871f44ea7540ad2bbd7a480ed197fe8a1c8a261075/ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/4d/c0/1108ad9f01567f66b3154063605b350b69c3c9366732e09e45f9fd0d1deb/safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (0.45.3)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/f9/b6/a447b5e4ec71e13871be01ba81f5dfc9d0af7e473da256ff46bc0e24026f/tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/7f/fc/5b29fea8cee020515ca82cc68e3b8e1e34bb19a3535ad854cac9257b414c/typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (4.12.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from gradio-client==1.7.2->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (15.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (1.4.8)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.3.dev0) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.3.dev0) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from pydantic->llamafactory==0.9.3.dev0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from pydantic->llamafactory==0.9.3.dev0) (2.27.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.51.1,>=4.41.2->llamafactory==0.9.3.dev0) (2024.11.6)\n",
      "Collecting docstring-parser>=0.16 (from tyro<0.9.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/d5/7c/e9fcff7623954d86bdc17782036cbf715ecab1bec4847c008557affe1ca8/docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Collecting rich>=11.1.0 (from tyro<0.9.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/0d/9b/63f4c7ebc259242c89b3acafdb37b41d1185c07ff0011164674e9076b491/rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro<0.9.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/e2/d1/a1d3189e7873408b9dc396aef0d7926c198b0df2aa3ddb5b539d3e89a70f/shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: click>=7.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from uvicorn->llamafactory==0.9.3.dev0) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from uvicorn->llamafactory==0.9.3.dev0) (0.14.0)\n",
      "Collecting termcolor (from fire->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/a6/7e/a574ccd49ad07e8b117407bac361f1e096b01f1b620365daf60ff702c936/termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/57/8d/30aa32745af16af0a9a650115fbe81bde7c610ed5c21b381fca0196f3a7f/audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Collecting numba>=0.51.0 (from librosa->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/e2/7d/bfb2805bcfbd479f04f835241ecf28519f6e3609912e3a985aed45e21370/numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting scikit-learn>=1.1.0 (from librosa->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/b7/91/ab3c697188f224d658969f678be86b0968ccc52774c8ab4a86a07be13c25/scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting joblib>=1.0 (from librosa->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from librosa->llamafactory==0.9.3.dev0) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/57/5e/70bdd9579b35003a489fc850b5047beeda26328053ebadc1fb60f320f7db/soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting pooch>=1.1 (from librosa->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/a8/87/77cc11c7a9ea9fd05503def69e3d18605852cd0d4b0d3b8f15bbeb3ef1d1/pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/ba/e6/059070b4cdb7fdd8ffbb67c5087c1da9716577127fb0540cd11dbf77923b/soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "Collecting lazy_loader>=0.1 (from librosa->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from librosa->llamafactory==0.9.3.dev0) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/zhangsh82/.local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from aiohttp->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.18.3)\n",
      "Requirement already satisfied: certifi in /home/zhangsh82/.local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /home/zhangsh82/.local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0) (1.0.7)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/aa/46/8ffbc114def88cc698906bf5acab54ca9fdf9214fe04aed0e71731fb3688/llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from pooch>=1.1->librosa->llamafactory==0.9.3.dev0) (4.3.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->llamafactory==0.9.3.dev0) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zhangsh82/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zhangsh82/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=3.5.0,>=2.16.0->llamafactory==0.9.3.dev0) (1.26.13)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.3.dev0) (2.19.1)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->librosa->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.3.dev0) (1.17.1)\n",
      "Requirement already satisfied: networkx in /home/zhangsh82/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zhangsh82/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate<=1.6.0,>=0.34.0->llamafactory==0.9.3.dev0) (1.3.0)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: pycparser in /home/zhangsh82/zsh/vllm/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.3.dev0) (2.22)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.3.dev0)\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: llamafactory, fire\n",
      "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llamafactory: filename=llamafactory-0.9.3.dev0-0.editable-py3-none-any.whl size=26304 sha256=b12ed5239322b790ad0e675a8195a164e50d0679d50762103656524e7ff80701\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-difkbbo3/wheels/53/42/6b/8d18ea2255ee854ac5018c106090ce331640b816915303476b\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25done\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114298 sha256=dc857792f6e7757800cc73163c7dfb709b72b82e8e8d0e653a556ca17beaa86f\n",
      "  Stored in directory: /home/zhangsh82/.cache/pip/wheels/51/ea/69/1d8b5c630ce54d8313336dcd10c5afdceb0065a864224babf3\n",
      "Successfully built llamafactory fire\n",
      "Installing collected packages: pydub, tomlkit, threadpoolctl, termcolor, soxr, shtab, shellingham, semantic-version, ruff, python-multipart, orjson, mdurl, llvmlite, lazy_loader, joblib, groovy, ffmpy, docstring-parser, av, audioread, aiofiles, soundfile, scikit-learn, pooch, numba, markdown-it-py, fire, sse-starlette, safehttpx, rich, librosa, gradio-client, tyro, typer, transformers, peft, gradio, trl, llamafactory\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.47.1\n",
      "    Uninstalling transformers-4.47.1:\n",
      "      Successfully uninstalled transformers-4.47.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autoawq 0.2.8 requires transformers<=4.47.1,>=4.45.0, but you have transformers 4.51.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-23.2.1 audioread-3.0.1 av-14.3.0 docstring-parser-0.16 ffmpy-0.5.0 fire-0.7.0 gradio-5.21.0 gradio-client-1.7.2 groovy-0.1.2 joblib-1.4.2 lazy_loader-0.4 librosa-0.11.0 llamafactory-0.9.3.dev0 llvmlite-0.44.0 markdown-it-py-3.0.0 mdurl-0.1.2 numba-0.61.2 orjson-3.10.16 peft-0.15.1 pooch-1.8.2 pydub-0.25.1 python-multipart-0.0.20 rich-14.0.0 ruff-0.11.4 safehttpx-0.1.6 scikit-learn-1.6.1 semantic-version-2.10.0 shellingham-1.5.4 shtab-1.7.1 soundfile-0.13.1 soxr-0.5.0.post1 sse-starlette-2.2.1 termcolor-3.0.1 threadpoolctl-3.6.0 tomlkit-0.13.2 transformers-4.51.1 trl-0.9.6 typer-0.15.2 tyro-0.8.14\n"
     ]
    }
   ],
   "source": [
    "!pip install -e \"/home/zhangsh82/data/zsh/LLaMA-Factory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70fed74a-c6a7-47b8-a25e-190d1e05c8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-11 10:16:51,975] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "----------------------------------------------------------\n",
      "| Welcome to LLaMA Factory, version 0.9.3.dev0           |\n",
      "|                                                        |\n",
      "| Project page: https://github.com/hiyouga/LLaMA-Factory |\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1222e21-9870-4806-86f9-8cc85f905ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-11 10:17:48,121] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Unknown command: --help.\n",
      "----------------------------------------------------------------------\n",
      "| Usage:                                                             |\n",
      "|   llamafactory-cli api -h: launch an OpenAI-style API server       |\n",
      "|   llamafactory-cli chat -h: launch a chat interface in CLI         |\n",
      "|   llamafactory-cli eval -h: evaluate models                        |\n",
      "|   llamafactory-cli export -h: merge LoRA adapters and export model |\n",
      "|   llamafactory-cli train -h: train models                          |\n",
      "|   llamafactory-cli webchat -h: launch a chat interface in Web UI   |\n",
      "|   llamafactory-cli webui: launch LlamaBoard                        |\n",
      "|   llamafactory-cli version: show version info                      |\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b70a814-286e-4568-8009-6b594a769c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhangsh82/data/zsh\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e4b7763-4f8a-475f-ac5d-de49712da6d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-11 15:02:06,127] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-04-11 15:02:08,242] [INFO] [comm.py:658:init_distributed] cdb=None\n",
      "INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[WARNING|2025-04-11 15:02:08] llamafactory.hparams.parser:148 >> `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.\n",
      "[INFO|2025-04-11 15:02:08] llamafactory.hparams.parser:379 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: True, compute dtype: torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2058] 2025-04-11 15:02:08,320 >> loading file vocab.json\n",
      "[INFO|tokenization_utils_base.py:2058] 2025-04-11 15:02:08,320 >> loading file merges.txt\n",
      "[INFO|tokenization_utils_base.py:2058] 2025-04-11 15:02:08,320 >> loading file tokenizer.json\n",
      "tokenization_utils_base.py:2058] 2025-04-11 15:02:08,320 >> loading file added_tokens.json\n",
      "enization_utils_base.py:2058] 2025-04-11 15:02:08,320 >> loading file special_tokens_map.json\n",
      "tokenization_utils_base.py:2058] 2025-04-11 15:02:08,320 >> loading file tokenizer_config.json\n",
      "|tokenization_utils_base.py:2058] 2025-04-11 15:02:08,320 >> loading file chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2323] 2025-04-11 15:02:08,682 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:691] 2025-04-11 15:02:08,683 >> loading configuration file /home/zhangsh82/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct/config.json\n",
      "[INFO|configuration_utils.py:765] 2025-04-11 15:02:08,684 >> Model config Qwen2Config {\n",
      "ures\": [tect\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "ken_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 896,\n",
      "  \"initializer_range\": 0.02,\n",
      "mediate_size\": 4864,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "\"qwen2\",_type\": \n",
      "  \"num_attention_heads\": 14,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 2,\n",
      "norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "ie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.1\",\n",
      "ache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2058] 2025-04-11 15:02:08,685 >> loading file vocab.json\n",
      "nization_utils_base.py:2058] 2025-04-11 15:02:08,685 >> loading file merges.txt\n",
      "tils_base.py:2058] 2025-04-11 15:02:08,685 >> loading file tokenizer.json\n",
      "ase.py:2058] 2025-04-11 15:02:08,685 >> loading file added_tokens.json\n",
      ".py:2058] 2025-04-11 15:02:08,685 >> loading file special_tokens_map.json\n",
      "ase.py:2058] 2025-04-11 15:02:08,685 >> loading file tokenizer_config.json\n",
      "base.py:2058] 2025-04-11 15:02:08,685 >> loading file chat_template.jinja\n",
      "[INFO|tokenization_utils_base.py:2323] 2025-04-11 15:02:08,992 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|2025-04-11 15:02:09] llamafactory.data.template:143 >> Add <|im_end|> to stop words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]: Traceback (most recent call last):\n",
      "src/llamafactory/data/parser.py\", line 107, in get_dataset_list\n",
      "as f:0]:     with open(config_path) \n",
      "[rank0]: FileNotFoundError: [Errno 2] No such file or directory: 'data/dataset_info.json'\n",
      "\n",
      "nk0]: During handling of the above exception, another exception occurred:\n",
      "\n",
      "recent call last): (most \n",
      "n <module> File \"/home/zhangsh82/data/zsh/LLaMA-Factory/src/train.py\", line 28, i\n",
      "[rank0]:     main()\n",
      ", line 19, in mainhome/zhangsh82/data/zsh/LLaMA-Factory/src/train.py\"\n",
      "[rank0]:     run_exp()\n",
      "c/llamafactory/train/tuner.py\", line 107, in run_expory/sr\n",
      " args, \"callbacks\": callbacks})(config={\"args\":\n",
      "tory/train/tuner.py\", line 69, in _training_functionory/src/llamafac\n",
      "ining_args, finetuning_args, generating_args, callbacks)\n",
      "LaMA-Factory/src/llamafactory/train/sft/workflow.py\", line 51, in run_sft\n",
      "e = get_dataset(template, model_args, data_args, training_args, stage=\"sft\", **tokenizer_module)\n",
      "nk0]:   File \"/home/zhangsh82/data/zsh/LLaMA-Factory/src/llamafactory/data/loader.py\", line 304, in get_dataset\n",
      "ining_args, stage)et = _get_merged_dataset(data_args.dataset, model_args, data_args, tra\n",
      "der.py\", line 178, in _get_merged_dataset/LLaMA-Factory/src/llamafactory/data/loa\n",
      "_names, get_dataset_list(dataset_names, data_args.dataset_dir)):\n",
      "ta/zsh/LLaMA-Factory/src/llamafactory/data/parser.py\", line 111, in get_dataset_list\n",
      "ise ValueError(f\"Cannot open {config_path} due to {str(err)}.\")\n",
      "a/dataset_info.json due to [Errno 2] No such file or directory: 'data/dataset_info.json'.\n",
      "[rank0]:[W411 15:02:09.499671807 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
      "E0411 15:02:10.586000 21905 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 22026) of binary: /home/zhangsh82/zsh/vllm/bin/python\n",
      "Traceback (most recent call last):\n",
      "e>File \"/home/zhangsh82/zsh/vllm/bin/torchrun\", line 8, in <modul\n",
      "    sys.exit(main())\n",
      "ted/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapperistribu\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/zhangsh82/zsh/vllm/lib/python3.10/site-packages/torch/distributed/run.py\", line 919, in main\n",
      "    run(args)\n",
      "\", line 910, in runsh82/zsh/vllm/lib/python3.10/site-packages/torch/distributed/run.py\n",
      "    elastic_launch(\n",
      "s/torch/distributed/launcher/api.py\", line 138, in __call__e\n",
      "lf._entrypoint, list(args))f._config, se\n",
      "ributed/launcher/api.py\", line 269, in launch_agente-packages/torch/dist\n",
      "    raise ChildFailedError(\n",
      "astic.multiprocessing.errors.ChildFailedError: \n",
      "====================================================\n",
      "LLaMA-Factory/src/train.py FAILED\n",
      "---------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "t Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-04-11_15:02:10\n",
      "-algot      : t-ai-platform\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 22026)\n",
      "  error_file: <N/A>\n",
      " To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "======================================\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\n#!/bin/bash\\nexport CUDA_VISIBLE_DEVICES=7\\n\\n# \\xe8\\xae\\xbe\\xe7\\xbd\\xae\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xe6\\x95\\xb0\\xe4\\xb8\\xba1\\nexport NNODES=1\\n# \\xe8\\xae\\xbe\\xe7\\xbd\\xae\\xe6\\xaf\\x8f\\xe4\\xb8\\xaa\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xe4\\xb8\\x8a\\xe7\\x9a\\x84GPU\\xe6\\x95\\xb0\\xe9\\x87\\x8f\\xe4\\xb8\\xba1\\nexport GPUS_PER_NODE=1\\n# \\xe8\\xae\\xbe\\xe7\\xbd\\xae\\xe5\\xbd\\x93\\xe5\\x89\\x8d\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xe7\\x9a\\x84\\xe7\\xad\\x89\\xe7\\xba\\xa7\\xe4\\xb8\\xba0\\nexport NODE_RANK=0\\n# \\xe8\\xae\\xbe\\xe7\\xbd\\xae\\xe4\\xb8\\xbb\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xe7\\x9a\\x84\\xe5\\x9c\\xb0\\xe5\\x9d\\x80\\xe4\\xb8\\xba\\xe6\\x9c\\xac\\xe5\\x9c\\xb0IP\\nexport MASTER_ADDR=localhost\\n# \\xe8\\xae\\xbe\\xe7\\xbd\\xae\\xe4\\xb8\\xbb\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xe7\\x9a\\x84\\xe7\\xab\\xaf\\xe5\\x8f\\xa3\\xe4\\xb8\\xba1234\\nexport MASTER_PORT=1234\\n\\nMODEL=\\'/home/zhangsh82/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct/\\'\\nOUTPUT_PATH=\\'/home/zhangsh82/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-zhenhuan\\'\\nDATA_SET=\\'zhenhuan\\'\\nDS_CONFIG_PATH=\\'/home/zhangsh82/data/zsh/LLaMA-Factory/examples/deepspeed/ds_z3_config.json\\'\\n\\n\\nDISTRIBUTED_ARGS=\"\\n    --nproc_per_node $GPUS_PER_NODE \\\\\\n    --nnodes $NNODES \\\\\\n    --node_rank $NODE_RANK \\\\\\n    --master_addr $MASTER_ADDR \\\\\\n    --master_port $MASTER_PORT\\n\"\\n\\ntorchrun $DISTRIBUTED_ARGS LLaMA-Factory/src/train.py \\\\\\n    --deepspeed $DS_CONFIG_PATH \\\\\\n    --stage sft \\\\\\n    --do_train \\\\\\n    --use_fast_tokenizer \\\\\\n    --flash_attn disabled \\\\\\n    --model_name_or_path $MODEL \\\\\\n    --dataset $DATA_SET \\\\\\n    --template qwen \\\\\\n    --finetuning_type lora \\\\\\n    --lora_target q_proj,v_proj\\\\\\n    --output_dir $OUTPUT_PATH \\\\\\n    --overwrite_cache \\\\\\n    --overwrite_output_dir \\\\\\n    --warmup_steps 100 \\\\\\n    --weight_decay 0.1 \\\\\\n    --per_device_train_batch_size 4 \\\\\\n    --gradient_accumulation_steps 4 \\\\\\n    --ddp_timeout 9000 \\\\\\n    --learning_rate 5e-6 \\\\\\n    --lr_scheduler_type cosine \\\\\\n    --logging_steps 1 \\\\\\n    --cutoff_len 4096 \\\\\\n    --save_steps 1000 \\\\\\n    --plot_loss \\\\\\n    --num_train_epochs 3 \\\\\\n    --fp16\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m#!/bin/bash\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mexport CUDA_VISIBLE_DEVICES=7\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# 设置节点数为1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mexport NNODES=1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# 设置每个节点上的GPU数量为1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mexport GPUS_PER_NODE=1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# 设置当前节点的等级为0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mexport NODE_RANK=0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# 设置主节点的地址为本地IP\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mexport MASTER_ADDR=localhost\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# 设置主节点的端口为1234\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mexport MASTER_PORT=1234\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mMODEL=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m/home/zhangsh82/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct/\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mOUTPUT_PATH=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m/home/zhangsh82/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-zhenhuan\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mDATA_SET=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mzhenhuan\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mDS_CONFIG_PATH=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m/home/zhangsh82/data/zsh/LLaMA-Factory/examples/deepspeed/ds_z3_config.json\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mDISTRIBUTED_ARGS=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --nproc_per_node $GPUS_PER_NODE \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --nnodes $NNODES \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --node_rank $NODE_RANK \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --master_addr $MASTER_ADDR \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --master_port $MASTER_PORT\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mtorchrun $DISTRIBUTED_ARGS LLaMA-Factory/src/train.py \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --deepspeed $DS_CONFIG_PATH \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --stage sft \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --do_train \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --use_fast_tokenizer \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --flash_attn disabled \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --model_name_or_path $MODEL \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --dataset $DATA_SET \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --template qwen \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --finetuning_type lora \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --lora_target q_proj,v_proj\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --output_dir $OUTPUT_PATH \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --overwrite_cache \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --overwrite_output_dir \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --warmup_steps 100 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --weight_decay 0.1 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --per_device_train_batch_size 4 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --gradient_accumulation_steps 4 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --ddp_timeout 9000 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --learning_rate 5e-6 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --lr_scheduler_type cosine \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --logging_steps 1 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --cutoff_len 4096 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --save_steps 1000 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --plot_loss \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --num_train_epochs 3 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    --fp16\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/zsh/vllm/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2543\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2541\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2542\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2543\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/zsh/vllm/lib/python3.10/site-packages/IPython/core/magics/script.py:159\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/zsh/vllm/lib/python3.10/site-packages/IPython/core/magics/script.py:336\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\n#!/bin/bash\\nexport CUDA_VISIBLE_DEVICES=7\\n\\n# \\xe8\\xae\\xbe\\xe7\\xbd\\xae\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xe6\\x95\\xb0\\xe4\\xb8\\xba1\\nexport NNODES=1\\n# \\xe8\\xae\\xbe\\xe7\\xbd\\xae\\xe6\\xaf\\x8f\\xe4\\xb8\\xaa\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xe4\\xb8\\x8a\\xe7\\x9a\\x84GPU\\xe6\\x95\\xb0\\xe9\\x87\\x8f\\xe4\\xb8\\xba1\\nexport GPUS_PER_NODE=1\\n# \\xe8\\xae\\xbe\\xe7\\xbd\\xae\\xe5\\xbd\\x93\\xe5\\x89\\x8d\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xe7\\x9a\\x84\\xe7\\xad\\x89\\xe7\\xba\\xa7\\xe4\\xb8\\xba0\\nexport NODE_RANK=0\\n# \\xe8\\xae\\xbe\\xe7\\xbd\\xae\\xe4\\xb8\\xbb\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xe7\\x9a\\x84\\xe5\\x9c\\xb0\\xe5\\x9d\\x80\\xe4\\xb8\\xba\\xe6\\x9c\\xac\\xe5\\x9c\\xb0IP\\nexport MASTER_ADDR=localhost\\n# \\xe8\\xae\\xbe\\xe7\\xbd\\xae\\xe4\\xb8\\xbb\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xe7\\x9a\\x84\\xe7\\xab\\xaf\\xe5\\x8f\\xa3\\xe4\\xb8\\xba1234\\nexport MASTER_PORT=1234\\n\\nMODEL=\\'/home/zhangsh82/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct/\\'\\nOUTPUT_PATH=\\'/home/zhangsh82/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-zhenhuan\\'\\nDATA_SET=\\'zhenhuan\\'\\nDS_CONFIG_PATH=\\'/home/zhangsh82/data/zsh/LLaMA-Factory/examples/deepspeed/ds_z3_config.json\\'\\n\\n\\nDISTRIBUTED_ARGS=\"\\n    --nproc_per_node $GPUS_PER_NODE \\\\\\n    --nnodes $NNODES \\\\\\n    --node_rank $NODE_RANK \\\\\\n    --master_addr $MASTER_ADDR \\\\\\n    --master_port $MASTER_PORT\\n\"\\n\\ntorchrun $DISTRIBUTED_ARGS LLaMA-Factory/src/train.py \\\\\\n    --deepspeed $DS_CONFIG_PATH \\\\\\n    --stage sft \\\\\\n    --do_train \\\\\\n    --use_fast_tokenizer \\\\\\n    --flash_attn disabled \\\\\\n    --model_name_or_path $MODEL \\\\\\n    --dataset $DATA_SET \\\\\\n    --template qwen \\\\\\n    --finetuning_type lora \\\\\\n    --lora_target q_proj,v_proj\\\\\\n    --output_dir $OUTPUT_PATH \\\\\\n    --overwrite_cache \\\\\\n    --overwrite_output_dir \\\\\\n    --warmup_steps 100 \\\\\\n    --weight_decay 0.1 \\\\\\n    --per_device_train_batch_size 4 \\\\\\n    --gradient_accumulation_steps 4 \\\\\\n    --ddp_timeout 9000 \\\\\\n    --learning_rate 5e-6 \\\\\\n    --lr_scheduler_type cosine \\\\\\n    --logging_steps 1 \\\\\\n    --cutoff_len 4096 \\\\\\n    --save_steps 1000 \\\\\\n    --plot_loss \\\\\\n    --num_train_epochs 3 \\\\\\n    --fp16\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#!/bin/bash\n",
    "export CUDA_VISIBLE_DEVICES=7\n",
    "\n",
    "# 设置节点数为1\n",
    "export NNODES=1\n",
    "# 设置每个节点上的GPU数量为1\n",
    "export GPUS_PER_NODE=1\n",
    "# 设置当前节点的等级为0\n",
    "export NODE_RANK=0\n",
    "# 设置主节点的地址为本地IP\n",
    "export MASTER_ADDR=localhost\n",
    "# 设置主节点的端口为1234\n",
    "export MASTER_PORT=1234\n",
    "\n",
    "MODEL='/home/zhangsh82/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct/'\n",
    "OUTPUT_PATH='/home/zhangsh82/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-zhenhuan'\n",
    "DATA_SET='zhenhuan'\n",
    "DS_CONFIG_PATH='/home/zhangsh82/data/zsh/LLaMA-Factory/examples/deepspeed/ds_z3_config.json'\n",
    "\n",
    "\n",
    "DISTRIBUTED_ARGS=\"\n",
    "    --nproc_per_node $GPUS_PER_NODE \\\n",
    "    --nnodes $NNODES \\\n",
    "    --node_rank $NODE_RANK \\\n",
    "    --master_addr $MASTER_ADDR \\\n",
    "    --master_port $MASTER_PORT\n",
    "\"\n",
    "\n",
    "torchrun $DISTRIBUTED_ARGS LLaMA-Factory/src/train.py \\\n",
    "    --deepspeed $DS_CONFIG_PATH \\\n",
    "    --stage sft \\\n",
    "    --do_train \\\n",
    "    --use_fast_tokenizer \\\n",
    "    --flash_attn disabled \\\n",
    "    --model_name_or_path $MODEL \\\n",
    "    --dataset $DATA_SET \\\n",
    "    --template qwen \\\n",
    "    --finetuning_type lora \\\n",
    "    --lora_target q_proj,v_proj\\\n",
    "    --output_dir $OUTPUT_PATH \\\n",
    "    --overwrite_cache \\\n",
    "    --overwrite_output_dir \\\n",
    "    --warmup_steps 100 \\\n",
    "    --weight_decay 0.1 \\\n",
    "    --per_device_train_batch_size 4 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --ddp_timeout 9000 \\\n",
    "    --learning_rate 5e-6 \\\n",
    "    --lr_scheduler_type cosine \\\n",
    "    --logging_steps 1 \\\n",
    "    --cutoff_len 4096 \\\n",
    "    --save_steps 1000 \\\n",
    "    --plot_loss \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49483bd4-b978-4800-8e98-cee648dad195",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=7 llamafactory-cli export \\\n",
    "    --model_name_or_path /home/zhangsh82/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-Instruct/ \\\n",
    "    --adapter_name_or_path /home/zhangsh82/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-zhenhuan \\\n",
    "    --template qwen \\\n",
    "    --finetuning_type lora \\\n",
    "    --export_dir /home/zhangsh82/.cache/modelscope/hub/models/Qwen/Qwen2.5-0.5B-zhenhuan-lora-merge \\\n",
    "    --export_size 2 \\\n",
    "    --export_legacy_format False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "vllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
